"Name:   Balin Banh, Samuel DindyalCourse: CPS506, Winter 2016, Assignment #2Due:    2016.02.28 23:59This is entirely our own work."Object subclass: #WebCrawler	instanceVariableNames: 'currentDepth maxDepth maxFollow url content tags parseObject client response contentType tagCounts globalTagCounts'	classVariableNames: ''	poolDictionaries: ''	category: 'CPS506A2'initializeWithURL:  urlIn withCurrentDepth: currentDepthIn maxPages: maxPathLengthIn andMaxDepth: maxDepthIn 	super initialize.	self.url := urlIn asZnUrl.	self.currentDepth := currentDepthIn.	self.maxDepth := maxDepthIn.	self.maxFollow := maxPathLengthIn.	self.parseObject := '[<][^/<>][^<>]*[>]' asRegexIgnoringCase.	self.tagCounts := Dictionary new.	self.globalTagCounts := Dictionary new. parseHtml	|str crawler tag lowerBound upperBound nextDepth followCount|	followCount := 0.	tags := parseObject matchesIn: content.	tags do: [  :each | 		lowerBound := 2.		upperBound := (each indexOfSubCollection:' ')-1.		(upperBound < 1)			ifTrue:[				upperBound := (each indexOfSubCollection:'>')-1.				].		tag := (each copyFrom:lowerBound to:upperBound) asLowercase.		(tagCounts includesKey:tag)		ifTrue:[			tagCounts at:tag put:(tagCounts at:tag)+1.			]		ifFalse:[			tagCounts at:tag put:1.			].		(each includesSubstring:'<a')		ifTrue: [  									lowerBound := ((each indexOfSubCollection:'href="')+6).				upperBound := ((each indexOfSubCollection:'"' startingAt:(each indexOfSubCollection:'href="')+6)-1).				(lowerBound > 0 & (upperBound < (each size)) & (lowerBound < upperBound) &(followCount < maxFollow))					ifTrue: [  						followCount  := followCount + 1.						str := each copyFrom:lowerBound to:upperBound.						(currentDepth < maxDepth)							ifTrue:[								(str includesSubstring:'http://')								ifTrue:[										crawler := WebCrawler new.									nextDepth := currentDepth+1.									crawler initializeWithURL:str withCurrentDepth:nextDepth maxPages:maxFollow andMaxDepth:maxDepth.									crawler fetchHtml.									self mergeCounts:(crawler parseHtml).								].							].						].					].				].						Transcript show: '-----------------------------------------'; cr.			Transcript show: 'URL: '.			Transcript show: url; cr.			Transcript show: '-----------------------------------------'; cr.			((tagCounts keys) asSortedCollection ) do: [ :each | 				Transcript show: each.				Transcript show: ' '.				Transcript show: (tagCounts at:each); cr.				].			(currentDepth = 0)				ifTrue: [ 					self mergeCounts: tagCounts.						Transcript show: '-----------------------------------------'; cr.						Transcript show: 'TOTAL COUNT'; cr.						Transcript show: '-----------------------------------------'; cr.						((globalTagCounts keys) asSortedCollection ) do: [ :each | 							Transcript show: each.							Transcript show: ' '.							Transcript show: (globalTagCounts at:each); cr.						].					 ].	^tagCounts mergeCounts:  tagCountIn	(tagCountIn keys) do: [ :each |			(globalTagCounts includesKey:each)				ifTrue: [ 							globalTagCounts at:each put:((globalTagCounts at:each) + (tagCountIn at:each)).					 ]				ifFalse: [ 						globalTagCounts at:each put:(tagCountIn at:each).					 ].		 ]. globalTagCounts	^globalTagCounts. fetchHtml	client := ZnClient new url: url.	client head.	response := client response.	contentType := response contentType.		(contentType matches: ZnMimeType textHtml)		ifTrue: [ 				client get.				content := client response entity contents.			 ]		ifFalse: [			  Transcript show: 'Could not get HTML from url:'.				Transcript show: url; cr.			]. 