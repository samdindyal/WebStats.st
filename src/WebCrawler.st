'From Pharo4.0 of 18 March 2013 [Latest update: #40626] on 28 February 2016 at 2:18:23.087027 am'!Object subclass: #WebCrawler	instanceVariableNames: 'currentDepth maxDepth maxFollow url content tags parseObject client response contentType tagCounts globalTagCounts'	classVariableNames: ''	poolDictionaries: ''	category: 'cps506'!!WebCrawler commentStamp: 'SamuelDindyal 2/28/2016 02:16' prior: 0!Name:   Balin Banh, Samuel DindyalCourse: CPS506, Winter 2016, Assignment #2Due:    2016.02.28 23:59This is entirely our own work.!!WebCrawler methodsFor: 'as yet unclassified' stamp: 'SamuelDindyal 2/28/2016 02:16'!parseHtml	|str crawler tag lowerBound upperBound nextDepth followCount|	followCount := 0.	tags := parseObject matchesIn: content.	tags do: [  :each | 		lowerBound := 2.		upperBound := (each indexOfSubCollection:' ')-1.		(upperBound < 1)			ifTrue:[				upperBound := (each indexOfSubCollection:'>')-1.				].		tag := each copyFrom:lowerBound to:upperBound.		(tagCounts includesKey:tag)		ifTrue:[			tagCounts at:tag put:(tagCounts at:tag)+1.			]		ifFalse:[			tagCounts at:tag put:1.			].		(each includesSubstring:'<a')		ifTrue: [  									lowerBound := ((each indexOfSubCollection:'href="')+6).				upperBound := ((each indexOfSubCollection:'"' startingAt:(each indexOfSubCollection:'href="')+6)-1).				(lowerBound > 0 & (upperBound < (each size)) & (lowerBound < upperBound) &(followCount < maxFollow))					ifTrue: [  						followCount  := followCount + 1.						str := each copyFrom:lowerBound to:upperBound.						(currentDepth < maxDepth)							ifTrue:[								(str includesSubstring:'http://')								ifTrue:[										crawler := WebCrawler new.									nextDepth := currentDepth+1.									crawler initializeWithURL:str withCurrentDepth:nextDepth maxPathLength:maxFollow andMaxDepth:maxDepth.									crawler fetchHtml.									self mergeCounts:(crawler parseHtml).								].							].						].					].				].						Transcript show: '-----------------------------------------'; cr.			Transcript show: 'URL: '.			Transcript show: url; cr.			Transcript show: '-----------------------------------------'; cr.			(tagCounts keys) do: [ :each | 				Transcript show: each.				Transcript show: ' '.				Transcript show: (tagCounts at:each); cr.				].			(currentDepth = 0)				ifTrue: [ 					self mergeCounts: tagCounts.						Transcript show: '-----------------------------------------'; cr.						Transcript show: 'TOTAL COUNT'; cr.						Transcript show: '-----------------------------------------'; cr.						(globalTagCounts keys) do: [ :each | 							Transcript show: each.							Transcript show: ' '.							Transcript show: (globalTagCounts at:each); cr.						].					 ].				^tagCounts! !!WebCrawler methodsFor: 'as yet unclassified' stamp: 'SamuelDindyal 2/28/2016 02:16'!mergeCounts:  tagCountIn	(tagCountIn keys) do: [ :each |			(globalTagCounts includesKey:each)				ifTrue: [ 							globalTagCounts at:each put:((globalTagCounts at:each) + (tagCountIn at:each)).					 ]				ifFalse: [ 						globalTagCounts at:each put:(tagCountIn at:each).					 ].		 ].! !!WebCrawler methodsFor: 'as yet unclassified' stamp: 'SamuelDindyal 2/28/2016 02:16'!globalTagCounts	^globalTagCounts.! !!WebCrawler methodsFor: 'as yet unclassified' stamp: 'SamuelDindyal 2/28/2016 02:16'!fetchHtml	client := ZnClient new url: url.	client head.	response := client response.	contentType := response contentType.		ZnMimeType textHtml.	ZnMimeType main: 'text' sub: 'html'.		(contentType matches: ZnMimeType textHtml)		ifTrue: [ 				client get.				content := client response entity contents.			 ]		ifFalse: [			  Transcript show: 'Could not get HTML from url:'.				Transcript show: url; cr.			].! !!WebCrawler methodsFor: 'as yet unclassified' stamp: 'SamuelDindyal 2/28/2016 02:16'!initializeWithURL:  urlIn withCurrentDepth: currentDepthIn maxPathLength: maxPathLengthIn andMaxDepth: maxDepthIn 	super initialize.	self.url := urlIn asZnUrl.	self.currentDepth := currentDepthIn.	self.maxDepth := maxDepthIn.	self.maxFollow := maxPathLengthIn.	self.parseObject := '[<][^!!/<>][^<>]*[>]' asRegexIgnoringCase.	self.tagCounts := Dictionary new.	self.globalTagCounts := Dictionary new.! !